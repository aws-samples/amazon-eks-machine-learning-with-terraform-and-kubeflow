{{- if .Values.framework }}
apiVersion: v1
kind: ConfigMap
metadata:
  name: framework-scripts-{{ .Release.Name }}
data:
{{- $frameworkGlob := printf "scripts/%s/*" .Values.framework }}
{{- range $path, $_ := .Files.Glob $frameworkGlob }}
  {{ base $path }}: |
{{ $.Files.Get $path | nindent 4 }}
{{- end }}
---
{{- end }}
apiVersion: ray.io/v1
kind: RayService
metadata:
  name: {{ .Release.Name }}
  labels:
    app.kubernetes.io/name: {{ .Release.Name }}
    app.kubernetes.io/instance: {{ .Release.Name }}
    app.kubernetes.io/managed-by: {{ .Release.Service }}
spec:
  serviceUnhealthySecondThreshold: {{ .Values.ray.service_unhealthy_threshold_secs }}
  deploymentUnhealthySecondThreshold: {{ .Values.ray.deployment_unhealthy_threshold_secs }}
  {{- .Values.ray.serve_config_v2 | toYaml | nindent 2 }}
  rayClusterConfig:
    rayVersion: {{ .Values.ray.version }}
    headGroupSpec:
      rayStartParams:
        dashboard-host: {{ .Values.ray.dashboard.host }}
      template:
        metadata:
          annotations:
            karpenter.sh/do-not-disrupt: "true"
            sidecar.istio.io/inject: 'false'
            app.kubernetes.io/instance: {{ .Release.Name }}
            app.kubernetes.io/managed-by: {{ .Release.Service }}
        spec:
          restartPolicy: {{  .Values.ray.restart_policy.head | default "OnFailure" }}
          containers:
          - name: ray-head
            image: {{ .Values.image }}
            imagePullPolicy: {{ .Values.image_pull_policy}} 
            ports:
            {{- range $v := .Values.ray.ports }}
              - name: {{ $v.name }}
                containerPort: {{ $v.port }}
            {{- end }}
            {{- if .Values.ray.env }}
            env:
              {{- range $v := .Values.ray.env }}
              - name: {{ $v.name }}
                value: "{{ tpl $v.value $ }}"
              {{- end }}
            {{- end }}
            volumeMounts:
              - mountPath: /dev/shm
                name: shm
              - mountPath: /etc/engine-config
                name: engine-config
              {{- if .Values.engine.code }}
              - mountPath: /etc/engine-code
                name: engine-code
              {{- end }}
              {{- if .Values.framework }}
              - mountPath: /etc/framework-scripts
                name: framework-scripts
              {{- end }}
              {{- if .Values.ray.logging.sidecar.enabled }}
              - mountPath: /tmp/ray
                name: ray-logs
              {{- end }}
              {{- $pv_index := 1 }}
              {{- range $pv := .Values.pvc }}
              - mountPath: {{ $pv.mount_path }}
                name: pv-{{ $pv_index }}
              {{- $pv_index = add $pv_index 1 }}
              {{- end }}
            resources:
              requests:
              {{- range $k, $v := .Values.ray.resources.requests }}
                {{ $k }}: {{ $v }}
              {{- end }}
              limits:
              {{- range $k, $v := .Values.ray.resources.limits }}
                {{ $k }}: {{ $v }}
              {{- end }}
          {{- if .Values.ray.logging.sidecar.enabled }}
          - name: log-streamer
            image: {{ .Values.ray.logging.sidecar.image | default "busybox:latest" }}
            command: ["/bin/sh", "-c"]
            args:
              - |
                while [ ! -d /tmp/ray/session_latest/logs ]; do sleep 2; done;
                exec tail -F /tmp/ray/session_latest/logs/serve/*.log /tmp/ray/session_latest/logs/*.log 2>/dev/null
            volumeMounts:
              - mountPath: /tmp/ray
                name: ray-logs
          {{- end }}
          volumes:
            - name: shm
              hostPath:
                path: /dev/shm
                type: Directory
            - name: engine-config
              configMap:
                defaultMode: 420
                name: engine-config-{{ .Release.Name }}
            {{- if .Values.engine.code }}
            - name: engine-code
              configMap:
                defaultMode: 420
                name: engine-code-{{ .Release.Name }}
            {{- end }}
            {{- if .Values.framework }}
            - name: framework-scripts
              configMap:
                defaultMode: 420
                name: framework-scripts-{{ .Release.Name }}
            {{- end }}
            {{- if .Values.ray.logging.sidecar.enabled }}
            - name: ray-logs
              emptyDir: {}
            {{- end }}
            {{- $pv_index := 1 }}
            {{- range $pv := .Values.pvc }}
            - name: pv-{{ $pv_index }}
              persistentVolumeClaim:
                claimName: {{ $pv.name }}
            {{- $pv_index = add $pv_index 1 }}
            {{- end }}
          {{- if .Values.ray.tolerations }}
          tolerations:
          {{- range $v := .Values.ray.tolerations }}
            - key: {{ $v.key }}
              {{- if $v.operator }}
              operator: "{{ $v.operator }}"
              {{- end }}
              {{- if $v.effect }}
              effect: "{{ $v.effect }}"
              {{- end }}
          {{- end }}
          {{- end }}
          {{- if .Values.ray.resources.node_type }}
          nodeSelector:
            node.kubernetes.io/instance-type: {{ .Values.ray.resources.node_type }}
          {{- end }}
    
    workerGroupSpecs:
    - replicas: {{ .Values.resources.min_replicas }}
      minReplicas: {{ .Values.resources.min_replicas }}
      maxReplicas: {{ .Values.resources.max_replicas }}
      numOfHosts: {{ .Values.resources.num_of_hosts | default 1 }}
      groupName: serving
      rayStartParams: {}
      template:
        metadata:
          labels:
            autoscaling-group: {{ $.Release.Name }}
          annotations:
            karpenter.sh/do-not-disrupt: "true"
            sidecar.istio.io/inject: 'false'
            app.kubernetes.io/instance: {{ $.Release.Name }}
            app.kubernetes.io/managed-by: {{ $.Release.Service }}
        spec:
          restartPolicy: {{  .Values.ray.restart_policy.worker | default "OnFailure" }}
          {{- if .Values.scheduler_name }}
          schedulerName: {{ .Values.scheduler_name }}
          {{- end }}
          containers:
          - name: ray-worker
            image: {{ .Values.image }}
            imagePullPolicy: {{ .Values.image_pull_policy}}
            lifecycle:
              preStop:
                exec:
                  command: [ "/bin/sh","-c","ray stop" ]
            {{- if .Values.ray.env }}
            env:
              {{- range $v := .Values.ray.env }}
              - name: {{ $v.name }}
                value: "{{ tpl $v.value $ }}"
              {{- end }}
            {{- end }}
            volumeMounts:
              - mountPath: /dev/shm
                name: shm
              - mountPath: /etc/engine-config
                name: engine-config
              {{- if .Values.engine.code }}
              - mountPath: /etc/engine-code
                name: engine-code
              {{- end }}
              {{- if .Values.framework }}
              - mountPath: /etc/framework-scripts
                name: framework-scripts
              {{- end }}
              {{- if .Values.ray.logging.sidecar.enabled }}
              - mountPath: /tmp/ray
                name: ray-logs
              {{- end }}
              {{- $pv_index := 1 }}
              {{- range $pv := .Values.pvc }}
              - mountPath: {{ $pv.mount_path }}
                name: pv-{{ $pv_index }}
              {{- $pv_index = add $pv_index 1 }}
              {{- end }}
            resources:
              requests:
              {{- range $k, $v := .Values.resources.requests }}
                {{ $k }}: {{ $v }}
              {{- end }}
              limits:
              {{- range $k, $v := .Values.resources.limits }}
                {{ $k }}: {{ $v }}
              {{- end }}
          {{- if .Values.ray.logging.sidecar.enabled }}
          - name: log-streamer
            image: {{ .Values.ray.logging.sidecar.image | default "busybox:latest" }}
            command: ["/bin/sh", "-c"]
            args:
              - |
                while [ ! -d /tmp/ray/session_latest/logs ]; do sleep 2; done;
                exec tail -F /tmp/ray/session_latest/logs/serve/*.log /tmp/ray/session_latest/logs/*.log 2>/dev/null
            volumeMounts:
              - mountPath: /tmp/ray
                name: ray-logs
          {{- end }}
          volumes:
            - name: shm
              hostPath:
                path: /dev/shm
                type: Directory
            - name: engine-config
              configMap:
                defaultMode: 420
                name: engine-config-{{ .Release.Name }}
            {{- if .Values.engine.code }}
            - name: engine-code
              configMap:
                defaultMode: 420
                name: engine-code-{{ .Release.Name }}
            {{- end }}
            {{- if .Values.framework }}
            - name: framework-scripts
              configMap:
                defaultMode: 420
                name: framework-scripts-{{ .Release.Name }}
            {{- end }}
            {{- if .Values.ray.logging.sidecar.enabled }}
            - name: ray-logs
              emptyDir: {}
            {{- end }}
            {{- $pv_index := 1 }}
            {{- range $pv := .Values.pvc }}
            - name: pv-{{ $pv_index }}
              persistentVolumeClaim:
                claimName: {{ $pv.name }}
            {{- $pv_index = add $pv_index 1 }}
            {{- end }}
          {{- if .Values.tolerations }}
          tolerations:
          {{- range $v := .Values.tolerations }}
            - key: {{ $v.key }}
              {{- if $v.operator }}
              operator: "{{ $v.operator }}"
              {{- end }}
              {{- if $v.effect }}
              effect: "{{ $v.effect }}"
              {{- end }}
          {{- end }}
          {{- end }}
          {{- if .Values.resources.node_type }}
          nodeSelector:
            node.kubernetes.io/instance-type: {{ .Values.resources.node_type }}
          {{- end }}