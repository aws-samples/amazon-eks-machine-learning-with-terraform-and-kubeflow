ray:
  version: '2.52.1'
  dashboard:
    host: '0.0.0.0'
  ports:
    - name: gcs
      port: 6379
    - name: client
      port: 10001
    - name: dashboard
      port: 8265
    - name: serve
      port: 8000
  resources:
    requests:
      cpu: 300m 
    limits:
      cpu: 2
  env:
    - name: RAY_LOGGING_LEVEL
      value: "ERROR"
    - name: RAY_enable_infeasible_task_early_exit
      value: "false"
    - name: NCCL_SOCKET_IFNAME 
      value: "^lo,docker0"
    - name: NCCL_DEBUG
      value: "WARN"
    - name: FI_EFA_USE_DEVICE_RDMA
      value: "1"
    - name: FI_PROVIDER
      value: "efa"
    - name: FI_EFA_FORK_SAFE
      value: "1"
    - name: "RDMAV_FORK_SAFE"
      value: "1"
  serve_config_v2: 
    serveConfigV2: |
      applications:
        - name: deepseek-r1
          import_path: openai_api:deployment
          runtime_env:
            env_vars:
              LD_LIBRARY_PATH: "/home/ray/anaconda3/lib/python3.12/site-packages/nvidia/cusparselt/lib:/usr/local/cuda/lib64"
              ENGINE_CONFIG: "/etc/engine-config/engine-config.json"
              PYTHONPATH: "/etc/framework-scripts"
            pip:
              - "vllm==0.15.0"
              - "pandas==2.3.0"
              - "pyarrow==21.0.0"
              - "transformers==4.57.6"
              - "scipy==1.17.0"
          deployments:
          - name: VLLMDeployment
            max_ongoing_requests: 64
            autoscaling_config:
              min_replicas: 1
              max_replicas: 1
              target_ongoing_requests: 32
  service_unhealthy_threshold_secs: 3600
  deployment_unhealthy_threshold_secs: 3600
engine:
  config:
    served_model_name: "deepseek-r1"
    model: "/fsx/pretrained-models/deepseek-ai/DeepSeek-R1"
    tokenizer: "/fsx/pretrained-models/deepseek-ai/DeepSeek-R1"
    tensor_parallel_size: 8
    pipeline_parallel_size: 6
    enable_log_requests: false
    disable_log_stats: true
    distributed_executor_backend: "ray"
image:
image_pull_policy: IfNotPresent
resources:
  min_replicas: 6
  max_replicas: 6
  requests:
    "nvidia.com/gpu": 8
    "vpc.amazonaws.com/efa": 4
  limits:
    "nvidia.com/gpu": 8
    "vpc.amazonaws.com/efa": 4
  node_type: 'p4de.24xlarge' 
tolerations:
  - key: "nvidia.com/gpu"
    operator: "Exists"
    effect: "NoSchedule"
pvc:
  - name: pv-fsx
    mount_path: /fsx
  - name: pv-efs
    mount_path: /efs
framework: vllm-0.15.0