image: public.ecr.aws/docker/library/python:slim-bullseye
inline_script:
- |+
  cat > /tmp/engine.json <<EOF
  {
    "model": "$MODEL_PATH",
    "disable_log_requests": true,
    "tensor_parallel_size": 8,
    "max_num_seqs": 4,
    "dtype": "auto",
    "max_model_len": 8192,
    "gpu_memory_utilization": 0.9,
    "enforce_eager": false,
    "enable_prefix_caching": true,
    "preemption_mode": "swap",
    "override_neuron_config": {
      "continuous_batching": {
        "max_num_seqs": 4,
        "optimized_paged_attention": true
      }
    }
  }

  EOF
pre_script:
  - mkdir -p $CONFIG_ROOT
  - chmod a+rwx $CONFIG_ROOT
  - cp /tmp/engine.json $CONFIG_ROOT/engine.json
process:
  env:
    - name: CONFIG_ROOT
      value: /efs/home/{{ .Release.Name }}/config
    - name: MODEL_PATH
      value: /fsx/pretrained-models/meta-llama/Meta-Llama-3-8B-Instruct
