image: 
  name:
  pull_policy: Always
framework: encoder_transformers
scheduler_name: neuron-scheduler
resources:
  node_type: inf2.xlarge
  resources:
  requests:
    "aws.amazon.com/neuron": 1
  limits:
    "aws.amazon.com/neuron": 1
tolerations:
  - key: "aws.amazon.com/neuron"
    operator: "Exists"
    effect: "NoSchedule"
inline_script:
- |+
  cat > /tmp/config.pbtxt <<EOF
  backend: "python"
  max_batch_size: 8
  model_transaction_policy {
    decoupled: false
  }
  dynamic_batching {
    max_queue_delay_microseconds: 1000
  }

  input [ 
    {
      name: "text_input"
      data_type: TYPE_STRING
      dims: [1]
    }
  ] 
  output [
    {
      name: "logits"
      data_type: TYPE_FP32
      dims: [-1]
    }
  ]

  instance_group [
    {
      count: 1
      kind: KIND_MODEL
    }
  ]
  
  EOF

  cat > /tmp/model.json <<EOF
    {
      "model_id_or_path": "$MODEL_PATH",
      "bucket_batch_size": [1,2,4,8],
      "bucket_seq_len": [16,32,64,128]
    }

  EOF

pre_script: 
  - LOG_ROOT=$HOME/logs
  - mkdir -p $LOG_ROOT
  - OUTPUT_LOG="$LOG_ROOT/triton-server.log"
  - MODEL_REPO=$HOME/model_repository
  - CACHE_DIR=$HOME/.cache
  - mkdir -p $CACHE_DIR
  - VERSION=1
  - MODEL_NAME=xml-roberta-base
  - mkdir -p $MODEL_REPO/$MODEL_NAME/$VERSION
  - cp $SCRIPTS_DIR/masked_lm.py $MODEL_REPO/$MODEL_NAME/$VERSION/model.py
  - cp $SCRIPTS_DIR/encoder_base.py $MODEL_REPO/$MODEL_NAME/$VERSION/encoder_base.py
  - cp /tmp/model.json $MODEL_REPO/$MODEL_NAME/$VERSION/model.json
  - cp /tmp/config.pbtxt $MODEL_REPO/$MODEL_NAME/config.pbtxt
  - export NEURON_CC_FLAGS="--model-type transformer --enable-fast-loading-neuron-binaries"
  - export NEURON_COMPILE_CACHE_URL=$CACHE_DIR
  - export TOKENIZERS_PARALLELISM="false"
server:
  ports:
    - name: 'http'
      value: '8000'
    - name: 'grpc'
      value: '8001'
    - name: 'metric'
      value: '8002'
  readiness_probe:
    period_secs: 30
    failure_threshold: 10
  startup_probe:
    period_secs: 60
    failure_threshold: 30
  liveness_probe:
    period_secs: 30
    failure_threshold: 10
  env:
    - name: HOME
      value: /efs/home/{{ .Release.Name }}
    - name: MODEL_PATH
      value: "/fsx/pretrained-models/FacebookAI/xlm-roberta-base"
    - name: SCRIPTS_DIR
      value: /etc/framework-scripts
  command:
    - tritonserver
  args:
    - --model-repository=${MODEL_REPO}
    - --grpc-port=8001
    - --http-port=8000
    - --metrics-port=8002
    - --disable-auto-complete-config
    - --log-file=$OUTPUT_LOG
  autoscaling:
    minReplicas: 1
    maxReplicas: 4
    metrics:
      - type: Pods
        pods:
          metric:
            name: avg_time_queue_us
          target:
            type: AverageValue
            averageValue: 50
