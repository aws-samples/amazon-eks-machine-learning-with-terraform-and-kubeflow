image: 
resources:
  requests:
    "nvidia.com/gpu": 1
  limits:
    "nvidia.com/gpu": 1
tolerations:
  - key: "nvidia.com/gpu"
    operator: "Exists"
    effect: "NoSchedule"
pre_script: 
  - SCRIPT_DIR=TensorRT-LLM/triton_backend
  - cd $SCRIPT_DIR
  - mkdir -p $LOG_ROOT
  - TP_SIZE=8
  - PP_SIZE=1
  - MODEL_NAME=mistral_7b_instruct
  - OUTPUT_LOG=$LOG_ROOT/${MODEL_NAME}_triton_model_tp_${TP_SIZE}_pp_${PP_SIZE}.log
  - TOKENIZER_DIR=$MODEL_PATH
  - DECOUPLED_MODE=false
  - MODEL_REPO=$OUTPUT_ROOT/model_repo
  - MAX_BATCH_SIZE=8
  - INSTANCE_COUNT=1
  - MAX_QUEUE_DELAY_MS=100
  - FILL_TEMPLATE_SCRIPT=tools/fill_template.py
  - ENGINE_DIR=$OUTPUT_ROOT/${MODEL_NAME}_engine_tp_${TP_SIZE}_pp_${PP_SIZE}
  - ENCODER_INPUT_DATA_TYPE=TYPE_BF16
  - mkdir -p $MODEL_REPO
  - rm -rf $MODEL_REPO/${MODEL_NAME}_*
  - cp -r all_models/inflight_batcher_llm/preprocessing $MODEL_REPO/${MODEL_NAME}_preprocessing
  - cp -r all_models/inflight_batcher_llm/postprocessing $MODEL_REPO/${MODEL_NAME}_postprocessing
  - cp -r all_models/inflight_batcher_llm/tensorrt_llm_bls $MODEL_REPO/${MODEL_NAME}_tensorrt_llm_bls
  - cp -r all_models/inflight_batcher_llm/ensemble $MODEL_REPO/${MODEL_NAME}_ensemble
  - cp -r all_models/inflight_batcher_llm/tensorrt_llm $MODEL_REPO/${MODEL_NAME}_tensorrt_llm
  - python3 ${FILL_TEMPLATE_SCRIPT} -i ${MODEL_REPO}/${MODEL_NAME}_preprocessing/config.pbtxt tokenizer_dir:${TOKENIZER_DIR},triton_max_batch_size:${MAX_BATCH_SIZE},preprocessing_instance_count:${INSTANCE_COUNT} 2>&1 | tee $OUTPUT_LOG
  - python3 ${FILL_TEMPLATE_SCRIPT} -i ${MODEL_REPO}/${MODEL_NAME}_postprocessing/config.pbtxt tokenizer_dir:${TOKENIZER_DIR},triton_max_batch_size:${MAX_BATCH_SIZE},postprocessing_instance_count:${INSTANCE_COUNT} 2>&1 | tee -a $OUTPUT_LOG
  - python3 ${FILL_TEMPLATE_SCRIPT} -i ${MODEL_REPO}/${MODEL_NAME}_tensorrt_llm_bls/config.pbtxt triton_max_batch_size:${MAX_BATCH_SIZE},decoupled_mode:${DECOUPLED_MODE},bls_instance_count:${INSTANCE_COUNT},tensorrt_llm_model_name:${MODEL_NAME}_tensorrt_llm 2>&1 | tee -a $OUTPUT_LOG
  - python3 ${FILL_TEMPLATE_SCRIPT} -i ${MODEL_REPO}/${MODEL_NAME}_ensemble/config.pbtxt triton_max_batch_size:${MAX_BATCH_SIZE} 2>&1 | tee -a $OUTPUT_LOG
  - python3 ${FILL_TEMPLATE_SCRIPT} -i ${MODEL_REPO}/${MODEL_NAME}_tensorrt_llm/config.pbtxt triton_max_batch_size:${MAX_BATCH_SIZE},decoupled_mode:${DECOUPLED_MODE},engine_dir:${ENGINE_DIR},max_queue_delay_microseconds:${MAX_QUEUE_DELAY_MS},batching_strategy:inflight_fused_batching,encoder_input_features_data_type:${ENCODER_INPUT_DATA_TYPE},triton_backend:tensorrtllm 2>&1 | tee -a $OUTPUT_LOG
  - "sed -i 's/name: \"preprocessing\"/name: \"mistral_7b_instruct_preprocessing\"/1' ${MODEL_REPO}/${MODEL_NAME}_preprocessing/config.pbtxt"
  - "sed -i 's/name: \"postprocessing\"/name: \"mistral_7b_instruct_postprocessing\"/1' ${MODEL_REPO}/${MODEL_NAME}_postprocessing/config.pbtxt"
  - "sed -i 's/name: \"tensorrt_llm_bls\"/name: \"mistral_7b_instruct_tensorrt_llm_bls\"/1' ${MODEL_REPO}/${MODEL_NAME}_tensorrt_llm_bls/config.pbtxt"
  - "sed -i 's/name: \"ensemble\"/name: \"mistral_7b_instruct_ensemble\"/1' ${MODEL_REPO}/${MODEL_NAME}_ensemble/config.pbtxt"
  - "sed -i 's/name: \"tensorrt_llm\"/name: \"mistral_7b_instruct_tensorrt_llm\"/1' ${MODEL_REPO}/${MODEL_NAME}_tensorrt_llm/config.pbtxt"
  - "sed -i 's/model_name: \"preprocessing\"/model_name: \"mistral_7b_instruct_preprocessing\"/1' ${MODEL_REPO}/${MODEL_NAME}_ensemble/config.pbtxt"
  - "sed -i 's/model_name: \"postprocessing\"/model_name: \"mistral_7b_instruct_postprocessing\"/1' ${MODEL_REPO}/${MODEL_NAME}_ensemble/config.pbtxt"
  - "sed -i 's/model_name: \"tensorrt_llm\"/model_name: \"mistral_7b_instruct_tensorrt_llm\"/1' ${MODEL_REPO}/${MODEL_NAME}_ensemble/config.pbtxt"
  - sed -i 's/${logits_datatype}/TYPE_FP32/g' ${MODEL_REPO}/${MODEL_NAME}_ensemble/config.pbtxt
  - sed -i 's/${logits_datatype}/TYPE_FP32/g' ${MODEL_REPO}/${MODEL_NAME}_tensorrt_llm/config.pbtxt
  - sed -i 's/${logits_datatype}/TYPE_FP32/g' ${MODEL_REPO}/${MODEL_NAME}_tensorrt_llm_bls/config.pbtxt
process:
  env:
    - name: LOG_ROOT
      value: /efs/home/{{ .Release.Name }}/logs
    - name: OUTPUT_ROOT
      value: /efs/home/{{ .Release.Name }}/trtllm
    - name: MODEL_PATH
      value: /fsx/pretrained-models/mistralai/Mistral-7B-Instruct-v0.1
