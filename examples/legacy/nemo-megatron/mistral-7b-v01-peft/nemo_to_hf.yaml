image: nvcr.io/nvidia/nemo:24.01.framework
resources:
  requests:
    "nvidia.com/gpu": 8
  limits:
    "nvidia.com/gpu": 8
  node_type: 'g6e.48xlarge' 
ebs:
  storage: 500Gi
  mount_path: /tmp
tolerations:
  - key: "nvidia.com/gpu"
    operator: "Exists"
    effect: "NoSchedule"
git:
  repo_url: 'https://github.com/NVIDIA/NeMo.git'
  branch: main
  commit: d2283e3620cd7f99dbe29fdf079757ab9f6cdf01
pre_script: 
  - pip install transformers==4.40.2
  - SCRIPT_DIR=scripts/nlp_language_modeling
  - cd $SCRIPT_DIR
  - mkdir -p $LOG_ROOT
  - OUTPUT_LOG=$LOG_ROOT/nemo_to_hf.log
  - TMP_OUTPUT_PATH=/tmp/hf_peft_model
  - PATH_TO_MERGED_MODEL=$LOG_ROOT/nemo_experiments/$EXP_NAME/checkpoints/merged_model.nemo
  - echo "PATH_TO_MERGED_MODEL=$PATH_TO_MERGED_MODEL"
post_script:
  - cp -r $TMP_OUTPUT_PATH $MODEL_PATH/
process:
  env:
    - name: LOG_ROOT
      value: /efs/home/{{ .Release.Name }}/logs
    - name: MODEL_PATH
      value: /fsx/pretrained-models/mistralai/Mistral-7B-v0.1
    - name: EXP_NAME
      value: peft_pubmedqa
  command:
    - python3
  args:
    - convert_mistral_7b_nemo_to_hf.py
    - --input_name_or_path=$PATH_TO_MERGED_MODEL
    - --output_path=$TMP_OUTPUT_PATH
    - --hf_model_name=$MODEL_PATH
    - '2>&1 | tee $OUTPUT_LOG'
