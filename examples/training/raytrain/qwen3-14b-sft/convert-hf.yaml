framework: ray_train
ray:
  version: '2.52.1'
  dashboard:
    host: '0.0.0.0'
  ports:
    - name: gcs-server
      port: 6379
    - name: client
      port: 10001
    - name: dashboard
      port: 8265
  resources:
    requests:
      cpu: 300m 
    limits:
      cpu: 2
  runtime_env_yaml:
    runtimeEnvYAML: |
      pip:
        - transformers==4.57.1 
        - datasets==4.4.1
        - peft==0.18.0 
        - sentencepiece==0.2.1
        - torchao==0.14.1
image:
image_pull_policy: Always
ebs:
  storage: 200Gi
  mount_path: /tmp
resources:
  requests:
    "nvidia.com/gpu": 8
  limits:
    "nvidia.com/gpu": 8
  nnodes: 1 
  node_type: 'g6e.48xlarge' 
tolerations:
  - key: "nvidia.com/gpu"
    operator: "Exists"
    effect: "NoSchedule"
pre_script:
    - mkdir -p $HOME/logs/$HOSTNAME
    - PROCESS_LOG=$HOME/logs/$HOSTNAME/convert_checkpoint_to_hf.log
    - cd $SCRIPTS_DIR
train:
  env:
    - name: HOME
      value: "/efs/home/{{ .Release.Name }}"
    - name: MODEL_PATH
      value: "/fsx/pretrained-models/Qwen/Qwen3-14B"
    - name: NCCL_SOCKET_IFNAME 
      value: "^lo,docker0"
    - name: NCCL_DEBUG
      value: "WARN"
    - name: FI_EFA_USE_DEVICE_RDMA
      value: "1"
    - name: FI_PROVIDER
      value: "efa"
    - name: FI_EFA_FORK_SAFE
      value: "1"
    - name: RDMAV_FORK_SAFE
      value: "1"
    - name: TRITON_CACHE_DIR
      value: /tmp
    - name: XDG_CACHE_HOME
      value: /tmp
    - name: SCRIPTS_DIR
      value: /etc/framework-scripts
  command:
    - python
  args:
    - convert_checkpoint_to_hf.py
    - --base_model="Qwen/Qwen3-14B"
    - --model_path=$MODEL_PATH
    - '2>&1 | tee $PROCESS_LOG' 
