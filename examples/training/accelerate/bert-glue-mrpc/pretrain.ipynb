{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-train BERT on GLUE MRPC Dataset using Accelerate\n",
    "\n",
    "This notebook shows how to pre-train BERT on the GLUE MRPC dataset using [Hugging Face Accelerate](https://github.com/huggingface/accelerate) library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install kubernetes\n",
    "! pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Set working directory\n",
    "os.chdir(os.path.expanduser('~/amazon-eks-machine-learning-with-terraform-and-kubeflow'))\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "\n",
    "# Get the src directory\n",
    "src_dir = os.path.join(os.getcwd(), \"src\")\n",
    "sys.path.insert(0, src_dir)\n",
    "\n",
    "from k8s.utils import wait_for_helm_release_pods\n",
    "\n",
    "# Get notebook directory\n",
    "notebook_dir = os.path.join(os.getcwd(), 'examples', 'training', 'accelerate', 'bert-glue-mrpc')\n",
    "print(f\"Notebook directory: {notebook_dir}\")\n",
    "\n",
    "# Initialize key variables\n",
    "release_name = 'accel-bert'\n",
    "namespace = 'kubeflow-user-example-com'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Launch Pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = [\n",
    "    'helm', 'install', '--debug', release_name,\n",
    "    'charts/machine-learning/training/pytorchjob-elastic',\n",
    "    '-f', f'{notebook_dir}/pretrain.yaml',\n",
    "    '-n', namespace\n",
    "]\n",
    "\n",
    "result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "print(result.stdout)\n",
    "if result.stderr:\n",
    "    print(\"STDERR:\", result.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for pre-training to complete\n",
    "wait_for_helm_release_pods(release_name, namespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uninstall the training job\n",
    "cmd = ['helm', 'uninstall', release_name, '-n', namespace]\n",
    "result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "print(result.stdout)\n",
    "if result.stderr:\n",
    "    print(\"STDERR:\", result.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output\n",
    "\n",
    "To access the output stored on EFS and FSx for Lustre file-systems:\n",
    "\n",
    "```bash\n",
    "kubectl apply -f eks-cluster/utils/attach-pvc.yaml -n kubeflow\n",
    "kubectl exec -it -n kubeflow attach-pvc -- /bin/bash\n",
    "```\n",
    "\n",
    "### Logs\n",
    "Pre-training logs are available in `/efs/home/accel-bert/logs` folder.\n",
    "\n",
    "### Checkpoints\n",
    "Pre-training checkpoints are available in `/efs/home/accel-bert/checkpoints` folder.\n",
    "\n",
    "### S3 Backup\n",
    "Any content stored under `/fsx` is automatically backed up to your configured S3 bucket."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
