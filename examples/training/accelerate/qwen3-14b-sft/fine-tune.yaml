image: 'nvcr.io/nvidia/pytorch:25.10-py3'
framework: 'accelerate'
ebs:
  storage: 200Gi
  mount_path: /tmp
resources:
  requests:
    "nvidia.com/gpu": 8
    "vpc.amazonaws.com/efa": 4
  limits:
    "nvidia.com/gpu": 8 
    "vpc.amazonaws.com/efa": 4
  nnodes: 2
  nproc_per_node: 8
  node_type: 'p4d.24xlarge'  
tolerations:
  - key: "nvidia.com/gpu"
    operator: "Exists"
    effect: "NoSchedule"
inline_script:
  - |+
    cat > /tmp/accel_config.yaml <<EOF
    compute_environment: LOCAL_MACHINE
    debug: true
    distributed_type: FSDP
    mixed_precision: bf16
    main_training_function: main
    num_machines: $PET_NNODES
    num_processes: $((PET_NPROC_PER_NODE * PET_NNODES ))
    machine_rank: $PET_NODE_RANK
    main_process_ip: $PET_MASTER_ADDR
    main_process_port: $PET_MASTER_PORT
    fsdp_config:
        fsdp_auto_wrap_policy: TRANSFORMER_BASED_WRAP
        fsdp_backward_prefetch: BACKWARD_PRE
        fsdp_cpu_ram_efficient_loading: true
        fsdp_forward_prefetch: false
        fsdp_offload_params: false  # Turn off for LoRA
        fsdp_sharding_strategy: FULL_SHARD
        fsdp_state_dict_type: SHARDED_STATE_DICT
        fsdp_sync_module_states: true
        fsdp_use_orig_params: true
        fsdp_activation_checkpointing: false
    EOF
pre_script: 
  - pip3 install --upgrade pip
  - pip3 install transformers==4.57.1 datasets==4.4.1 peft==0.18.0 
        accelerate==1.12.0 tensorboard==2.20.0 sentencepiece==0.2.1 torchao==0.14.1
        wandb==0.23.0 mpi4py==4.1.1
  - cat /tmp/accel_config.yaml
  - mkdir -p $HOME/logs/$PET_NODE_RANK
  - PROCESS_LOG=$HOME/logs/$PET_NODE_RANK/fine_tune.log
  - cd $SCRIPTS_DIR
train:
  env:
    - name: HOME
      value: "/efs/home/{{ .Release.Name }}"
    - name: MODEL_PATH
      value: "/fsx/pretrained-models/Qwen/Qwen3-14B"
    - name: NCCL_SOCKET_IFNAME 
      value: "^lo,docker0"
    - name: NCCL_DEBUG
      value: "WARN"
    - name: FI_EFA_USE_DEVICE_RDMA
      value: "1"
    - name: FI_PROVIDER
      value: "efa"
    - name: FI_EFA_FORK_SAFE
      value: "1"
    - name: RDMAV_FORK_SAFE
      value: "1"
    - name: TRITON_CACHE_DIR
      value: /tmp
    - name: XDG_CACHE_HOME
      value: /tmp
    - name: SCRIPTS_DIR
      value: /etc/framework-scripts
  command:
    - accelerate
  args:
    - launch
    - --config_file
    - /tmp/accel_config.yaml
    - fine_tune.py
    - --hf_model_id="Qwen/Qwen3-14B"
    - --model_path=$MODEL_PATH
    - --max_steps=10000
    - --per_device_train_batch_size=2
    - --per_device_eval_batch_size=2
    - --gradient_accumulation_steps=2
    - --eval_steps=100
    - --max_eval_samples=640
    - --early_stopping_threshold=0.0001
    - --early_stopping_patience=3
    - '2>&1 | tee $PROCESS_LOG' 
